{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Loading some essential libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.preprocessing import image\nfrom keras.applications import xception\nfrom keras.layers import Dense,Dropout\nimport os\nfrom tqdm import tqdm\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Find the Categories of the species in the dataset**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"Category = np.sort(os.listdir('../input/plant-seedlings-classification/train'))\nCategory","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bed5f5cd8d499e09d63ec3e3c3e9a612a937c1a","_cell_guid":"6716d890-6ed0-40a5-b141-12b2e605af36","trusted":true},"cell_type":"code","source":"data_dir = '../input/plant-seedlings-classification/'\ntrain_dir = '../input/plant-seedlings-classification/train'\ntest_dir = '../input/plant-seedlings-classification/test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's look at the distribution of the images with this category**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\ndir_list = []\nfor c in Category:\n    files = check_output([\"ls\", \"../input/plant-seedlings-classification/train/%s\" % c]).decode(\"utf8\").strip().split(\"\\n\")\n    dir_list.append(files)\n    files = check_output([\"ls\", \"-l\", \"../input/plant-seedlings-classification/train/%s\" % c]).decode(\"utf8\").strip().split(\"\\n\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"n_images\": [len(x) for x in dir_list]}, index=Category)\ndf.plot(kind=\"barh\", figsize=(5,7), color='green')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"753661ccbdd246eccd978554b7a7cfbc6a5573c2","_cell_guid":"69f89f06-0683-4723-a12e-eb2b9c80487d","trusted":true},"cell_type":"code","source":"train = []\nfor label, category in enumerate(Category):\n    for file in os.listdir(os.path.join(train_dir, category)):\n        imag = image.load_img(os.path.join(train_dir,category, file))\n        train.append(['train/{}/{}'.format(category, file), label, category])\n        #train.append(['train/{}/{}'.format(category, file), label, category,imag.size])\n        \ntrain = pd.DataFrame(train, columns=['file', 'label', 'category'])\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To pickup the number of images to train we will pick the number minimum number of all 12 species.**"},{"metadata":{"_uuid":"f04df22cf8fd8b10eb1c6692f18cc6507f5d8e7b","_cell_guid":"90b5c14b-c830-4ad2-a726-70fd0fd76668","trusted":true},"cell_type":"code","source":"uniq, count = np.unique(train['label'], return_counts=True)\nuniq = [Category[c] for c in uniq]\nuniq_data = np.c_[uniq,count]\nuniq_data = pd.DataFrame(uniq_data,columns=['Labels','Count'])\nlowest_num_of_samples = min(count)\nuniq_data.head(12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"234f1a42c86870bacf43d06579b7ba4153a9b4ef","_cell_guid":"9bc2b62f-e570-44d8-a119-3b5cfa602ee8"},"cell_type":"markdown","source":"\n**For each Class Loading the lowest number of samples the a species has and resizing all the image to the same size and Pre proccesing  images  for the Xception model.**"},{"metadata":{"_uuid":"c8413af66639628fa3fbc83e80b4939bc0c716b3","_cell_guid":"6c949dc4-4528-4153-be3c-d20b1ed64965","trusted":true},"cell_type":"code","source":"i = 0 \nm = 0\nX_train = np.zeros((lowest_num_of_samples*12,299,299,3))\nlabels = np.zeros((lowest_num_of_samples*12),dtype=np.int)\nfor cat in tqdm(Category):\n    c = 0\n    for file in os.listdir(os.path.join(train_dir, cat)):\n        imag = image.load_img(os.path.join(train_dir,cat, file),target_size=(299,299))\n        imag = image.img_to_array(imag)\n        imag = xception.preprocess_input(np.expand_dims(imag.copy(), axis=0))\n        c += 1\n        if c <= lowest_num_of_samples:\n            X_train[m] = imag\n            labels[m] = i\n            m +=1\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27024a04f7e2ea3977489ece710f92edc195ceab","_cell_guid":"4e2f261a-1210-4dd6-8d58-072258c21490","trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32f99293aa85a30e72614f0e85b8a22602b6094a","_cell_guid":"41a807a7-4424-4c21-b26f-fd2790a44fe7","trusted":true},"cell_type":"code","source":"X_train,labels = shuffle(X_train,labels,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Divide the dataset into Training and Validation set**"},{"metadata":{"_uuid":"b908ccbdff8f97a77a28cb7ff8a6c2e11e164fa9","_cell_guid":"d82c122c-a0a5-46ac-a2ca-224f6757a8de","trusted":true},"cell_type":"code","source":"X_train, X_Val, Y_train, Y_Val = train_test_split(X_train, labels, test_size=0.1, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will use the flags for blurring training set and validation set.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"blur_train = False\nblur_valid = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.misc\nfrom scipy import ndimage\n\nif blur_train:\n    X_train = ndimage.gaussian_filter(X_train, sigma=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.misc\nfrom scipy import ndimage\n\nif blur_valid:\n    X_Val = ndimage.gaussian_filter(X_Val, sigma=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extract features using xception model**"},{"metadata":{"_uuid":"147c3caba932907d919b8b549b7a9d45221a44da","_cell_guid":"d80b1d78-fc35-4075-a2f9-17c54e48610b","trusted":true},"cell_type":"code","source":"xception_model = xception.Xception(weights='../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, pooling='avg')\nX_train = xception_model.predict(X_train,batch_size=32,verbose = 1)\nX_Val = xception_model.predict(X_Val,batch_size=32,verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 1897\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlogreg.fit(X_train, Y_train)\nvalid_probs = logreg.predict_proba(X_Val)\nvalid_preds = logreg.predict(X_Val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nprint('Validation Xception Accuracy {}'.format(accuracy_score(Y_Val, valid_preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnf_matrix = confusion_matrix(Y_Val, valid_preds)\ncnf_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nytrOCL = keras.utils.to_categorical(Y_train, num_classes=12)\nyvOCL = keras.utils.to_categorical(Y_Val, num_classes=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.ensemble\nrandom_forest = sklearn.ensemble.RandomForestClassifier(n_estimators=10)\n\nrandom_forest.fit(X_train, ytrOCL)\n\nacc_train_random_forest = random_forest.score(X_train, ytrOCL)\nacc_valid_random_forest = random_forest.score(X_Val,yvOCL )\n\nprint('Random Forest')\nprint('Accuracy train/valid = %.4f/%.4f'%(acc_train_random_forest, acc_valid_random_forest))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SVC model**"},{"metadata":{"_uuid":"e3f814c9f052532797ffaf976dcebf65464c0b58","_cell_guid":"b2ceb3ad-49bf-409d-865a-d8e5d36c9e24","trusted":true},"cell_type":"code","source":"model = SVC()\nmodel.fit(X_train,Y_train)\ntrain_pred = model.predict(X_train)\nval_pred = model.predict(X_Val)\ntraining_acc = f1_score(Y_train,train_pred,average='micro')\nval_acc = f1_score(Y_Val, val_pred,average='micro')    \nprint('Traning score :: {}'.format(training_acc))\nprint('Validation Score :: {}'.format(val_acc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4aa01a306c5b634c40da24d0265093a699b70c5c","_cell_guid":"4f69e00d-4d16-432c-9383-a0c75c04d13c","trusted":true},"cell_type":"code","source":"Y_train = np.eye(12)[Y_train]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Augmentation** and flag whether we want to use data augmentation or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ngen = ImageDataGenerator(\n            rotation_range=360.,\n            width_shift_range=0.3,\n            height_shift_range=0.3,\n            zoom_range=0.3,\n            horizontal_flip=True,\n            vertical_flip=True)\n\ntrain_generator = gen.flow_from_directory(\n                        train_dir,\n                        target_size = (299,299),\n                        batch_size = 32, \n                        class_mode = \"categorical\", subset='training')\n\ndata_augmentation = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Deep learning model to use augmented dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xception_model = xception.Xception(weights='../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False,  input_shape=(299, 299, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import applications\nmodel = applications.Xception(weights='../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape = (299, 299, 3))\nfor layer in model.layers[:5]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation=\"relu\")(x)\npredictions = Dense(12, activation=\"softmax\")(x) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential, Model \nfrom keras import optimizers\nmodel_final = Model(input = model.input, output = predictions)\n#compling our model\nmodel_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_final.summary() #Model summary'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if data_augmentation: \n    model_final.fit_generator(train_generator,epochs = 5,shuffle= True,steps_per_epoch = 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Testing data augmentation model with the test images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if data_augmentation:\n    test = []\n    for file in os.listdir(test_dir):\n        test.append(['test/{}'.format(file), file])\n    test = pd.DataFrame(test, columns=['filepath', 'file'])\n    test.head(2)\n    test.shape\n    classes = train_generator.class_indices  \n    print(classes)\n    classes = {v: k for k, v in classes.items()}\n    print(classes)\n    prediction = []\n    for filepath in test['filepath']:\n        img = cv2.imread(os.path.join(data_dir,filepath))\n        img = cv2.resize(img,(299,299))\n        img = np.asarray(img)\n        img = img.reshape(1,299,299,3)\n        pred = model_final.predict(img)\n\n        prediction.append(classes.get(pred.argmax(axis=-1)[0])) #Invert Mapping helps to map Label\n\n    test = test.drop(columns =['filepath'])\n    pred = pd.DataFrame({'species': prediction})\n    test =test.join(pred)\n    test.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''from keras import layers, models, regularizers, optimizers\nfrom keras.models import Sequential,  Model\nfrom keras.layers import Flatten, Dense, Dropout\n\nmodel = models.Sequential()\nmodel.add(xception_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(12, activation='sigmoid'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(rate=0.3))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(rate=0.3))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(12, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.90),\n              metrics=['acc'])\nmodel.summary()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import GaussianNoise","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Deep learning model for non augmented  data**"},{"metadata":{"_uuid":"60b184d5a9bac829b05ce33dceaad66a36ee76ae","_cell_guid":"60bff511-5992-49bc-a6cf-ac64e9dcc640","trusted":true},"cell_type":"code","source":"new_model = Sequential()\nnew_model.add(Dense(1024, activation='relu', input_shape=(2048,)))\nnew_model.add(GaussianNoise(0.1))\nnew_model.add(Dense(512, activation='relu'))\nnew_model.add(Dropout(rate=0.3))\nnew_model.add(Dense(256, activation='relu'))\nnew_model.add(Dense(128, activation='relu'))\nnew_model.add(Dropout(rate=0.3))\nnew_model.add(Dense(64, activation='relu'))\nnew_model.add(Dense(12, activation='softmax'))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b4ec23da8b9a42d18ecf19d91925313ff7f5d64","_cell_guid":"63f65cf7-0d00-430e-aa1a-925efd6c287d","trusted":true},"cell_type":"code","source":"new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2516f56a1e036fbb144daf86bfa78da055ccfb4","_cell_guid":"cb36e382-26a4-42ae-bf15-0bf9d436e889","trusted":true},"cell_type":"code","source":"if not data_augmentation:\n    new_model.fit(X_train, Y_train, epochs = 30, batch_size = 16)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50941863545c85d6405d8ecd1564fe0aad140f0c","_cell_guid":"13d0a30e-d714-445b-8006-564f152801a9","trusted":true},"cell_type":"code","source":"Y_pred = new_model.predict(X_Val)\nY_pred = np.argmax(Y_pred, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = f1_score(Y_Val, Y_pred,average='micro')\nprint('The F1score on the Validation set is {}'.format(acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test the logistic regression model with the test images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = []\nfor file in os.listdir(test_dir):\n    test.append(['test/{}'.format(file), file])\ntest = pd.DataFrame(test, columns=['filepath', 'file'])\ntest.head(2)\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.zeros((len(test), 299, 299, 3), dtype='float32')\nfor i, filepath in tqdm(enumerate(test['filepath'])):\n    img = image.load_img(os.path.join(data_dir, filepath), target_size=(299,299))\n    img = image.img_to_array(img)\n   \n    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_test[i] = x\nprint('test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x_bf = xception_model.predict(x_test, batch_size=32, verbose=1)\nprint('Xception test bottleneck features shape: {} size: {:,}'.format(test_x_bf.shape, test_x_bf.size))\ntest_preds = logreg.predict(test_x_bf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = logreg.predict(test_x_bf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['category_id'] = test_preds\ntest['species'] = [Category[c] for c in test_preds]\ntest[['file', 'species']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['file', 'species']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test the sequential model with the test images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = new_model.predict(test_x_bf)\ntest_preds = np.argmax(test_preds, axis = 1)\ntest['category_id'] = test_preds\ntest['species'] = [Category[c] for c in test_preds]\ntest[['file', 'species']].to_csv('submission1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['file', 'species']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**References:**"},{"metadata":{},"cell_type":"markdown","source":"* https://medium.com/@gkadusumilli/image-recognition-using-pre-trained-xception-model-in-5-steps-96ac858f4206\n* https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/\n* https://www.researchgate.net/post/How_to_implement_Pre-trained_models_with_only_modifications_in_the_output_layer\n* https://www.kaggle.com/baohuy/data-augmentation-pre-trained-xception-0-4\n* https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n* https://www.kaggle.com/zhoulingyan0228/seedling-classification-cnn-w-data-augmnt\n* https://www.kaggle.com/oysteijo/just-some-simple-train-data-investigation\n* https://www.kaggle.com/gaborfodor/seedlings-pretrained-keras-models\n* https://www.kaggle.com/omkarsabnis/seedling-classification-using-cnn-v13-0-95\n* https://www.kaggle.com/ashishpatel26/plant-seed-classification-using-vgg16\n* https://www.kaggle.com/limitpointinf0/crop-vs-weeds\n* https://www.kaggle.com/mnehete32/plant-seedlings-classification-pretrained-model\n* https://www.kaggle.com/raoulma/plants-xception-90-06-test-accuracy\n* https://www.kaggle.com/solomonk/pytorch-simplenet-augmentation-cnn-lb-0-945\n* https://www.kaggle.com/atrisaxena/keras-plant-seedlings-vgg19-augmentation\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}